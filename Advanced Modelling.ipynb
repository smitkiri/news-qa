{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling\n",
    "\n",
    "Now that we have a baseline model, we can move on to the \"Software 2.0\" approach where we train machine learning models. The data pre-processing code can be found in the file 'newsqa.py'. Please refer to that file before looking at this code. \n",
    "\n",
    "**Preprocessing:**\n",
    "\n",
    "We create a NewsQaExample object for each input example which stores all details like the tokens, index mappings, labels and others. Code referenced for pre-processing: https://github.com/chiayewken/bert-qa.\n",
    "\n",
    "Challenges addressed in preprocessing:\n",
    "\n",
    "- Handling data that exceeds BERT maximum token length. For training data, we use a sliding window to find the part of the text which has the answer and use that as out input. For test data, we use all the windows and get answers for each window.\n",
    "\n",
    "- Maintaining token -> original word indices and word -> character indices.\n",
    "\n",
    "**Modelling:**\n",
    "\n",
    "The training code can be found in 'newsqa.py'. We create a NewsQaModel object which stores the model and handles training and evaluation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9150b2f9b0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from newsqa import NewsQaExample, NewsQaModel, create_dataset, get_single_prediction\n",
    "import utils\n",
    "\n",
    "from transformers import BertTokenizer, BertForQuestionAnswering\n",
    "from transformers import DistilBertTokenizer, DistilBertForQuestionAnswering\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the data\n",
    "NEWS_STORIES = utils.open_pickle('data/news_stories.pkl')\n",
    "data = pd.read_csv('data/newsqa-dataset-cleaned.csv')\n",
    "total_examples = len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_examples():\n",
    "    '''\n",
    "    Return a list of NewsQaExample objects\n",
    "    '''\n",
    "    # If a pickle file exists for examples, read the file\n",
    "    if os.path.isfile('data/examples.pkl'):\n",
    "        return utils.open_pickle('data/examples.pkl')\n",
    "    \n",
    "    examples = []\n",
    "\n",
    "    for idx, row in data.iterrows():\n",
    "        ex = NewsQaExample(NEWS_STORIES[row['story_id']], row['question'], row['start_idx'], row['end_idx'])\n",
    "        examples.append(ex)\n",
    "        utils.drawProgressBar(idx + 1, total_examples)\n",
    "    \n",
    "    print('\\n')\n",
    "    # Saving examples to a pickle file\n",
    "    utils.save_pickle('data/examples.pkl', examples)\n",
    "    \n",
    "    return examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets(examples, tokenizer_name):\n",
    "    '''\n",
    "    Returns train, val and test datasets from examples\n",
    "    \n",
    "    Parameters\n",
    "    ------------\n",
    "    examples: list\n",
    "              A list of NewsQaExample objects\n",
    "              \n",
    "    tokenizer_name: str\n",
    "                    The tokenizer to use\n",
    "    '''\n",
    "    model_name = tokenizer_name.split('-')[0]\n",
    "    \n",
    "    if os.path.isfile('data/dataset_' + model_name + '.pkl'):\n",
    "        return utils.open_pickle('data/dataset_' + model_name + '.pkl')\n",
    "    \n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    if tokenizer_name == 'bert-large-uncased-whole-word-masking-finetuned-squad':\n",
    "        tokenizer = BertTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    if tokenizer_name == 'distilbert-base-uncased-distilled-squad':\n",
    "        tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_name)\n",
    "    \n",
    "    print(\"Getting input features:\")\n",
    "    for idx, ex in enumerate(examples):\n",
    "        input_features = ex.encode_plus(tokenizer, pad = True)\n",
    "        features.append(input_features)\n",
    "        labels.append(ex.get_label())\n",
    "        utils.drawProgressBar(idx + 1, total_examples)\n",
    "    \n",
    "    # Getting TensorDataset\n",
    "    train_set, val_set, test_set, feature_idx_map = create_dataset(features, labels, model = model_name)\n",
    "    # Saving the dataset in a file\n",
    "    utils.save_pickle('data/dataset_' + model_name + '.pkl', (train_set, val_set, test_set, feature_idx_map))\n",
    "    \n",
    "    return (train_set, val_set, test_set, feature_idx_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(train_set, val_set, test_set, batch_size):\n",
    "    '''\n",
    "    Creates torch dataloaders for train, validation and test sets\n",
    "    '''\n",
    "    train_loader = DataLoader(train_set, batch_size = BATCH_SIZE, \n",
    "                          sampler = RandomSampler(train_set))\n",
    "\n",
    "    val_loader = DataLoader(val_set, batch_size = BATCH_SIZE, \n",
    "                            sampler = SequentialSampler(val_set))\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size = BATCH_SIZE, \n",
    "                             sampler = SequentialSampler(test_set))\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def finetune_model(model_name, train_loader, val_loader, feature_idx_map, device, \n",
    "                   epochs = 1, learning_rate = 1e-5):\n",
    "    '''\n",
    "    Fine-tunes a pretrained model\n",
    "    '''\n",
    "    if model_name == 'bert-large-uncased-whole-word-masking-finetuned-squad':\n",
    "        model = BertForQuestionAnswering.from_pretrained(model_name)\n",
    "        # Freezing bert parameters\n",
    "        for param in model.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "    if model_name == 'distilbert-base-uncased-distilled-squad':\n",
    "        model = DistilBertForQuestionAnswering.from_pretrained(model_name)\n",
    "        # Freezing distilbert parameters\n",
    "        for param in model.distilbert.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "    short_name = model_name.split('-')[0]\n",
    "    \n",
    "    newsqa_model = NewsQaModel(model)\n",
    "    newsqa_model.train(train_loader, val_loader, feature_idx_map, device, \n",
    "                       num_epochs = epochs, lr = learning_rate, \n",
    "                       filename = 'data/' + short_name + '_model.pt')\n",
    "    \n",
    "    return newsqa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of NewsQaExample objects\n",
    "examples = get_examples()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained-BERT\n",
    "\n",
    "We use the bert-large-uncased-whole-word-masking-finetuned-squad pretrained model which is trained specifically for question answering task and will be quick to fine-tune on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name\n",
    "bert_model_name = 'bert-large-uncased-whole-word-masking-finetuned-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the training, validation and test sets\n",
    "bert_datasets = get_datasets(examples, bert_model_name)\n",
    "bert_train_set, bert_val_set, bert_test_set, bert_feature_idx_map = bert_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "bert_loaders = get_dataloaders(bert_train_set, bert_val_set, bert_test_set, batch_size = BATCH_SIZE)\n",
    "bert_train_loader, bert_val_loader, bert_test_loader = bert_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2:\n",
      "Progress: [====================] 1921/1921  65m 5s\tloss: 3.5983\tf1: 0.2767\tacc: 0.4723\tval_loss: 3.3842\tval_f1: 0.3194\tval_acc: 0.5074\n",
      "Validation accuracy increased from 0.0000 to 0.5074, saving to models/bert.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/2:\n",
      "Progress: [====================] 1921/1921  65m 5s\tloss: 3.5233\tf1: 0.2809\tacc: 0.4747\tval_loss: 3.3854\tval_f1: 0.3301\tval_acc: 0.5242\n",
      "Validation accuracy increased from 0.4723 to 0.5242, saving to models/bert.pt\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 2\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "bert_model = finetune_model(bert_model_name, bert_train_loader, bert_val_loader, bert_feature_idx_map, \n",
    "                            device, epochs = EPOCHS, learning_rate = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 549/549\n",
      "loss: 3.3887\tf1:0.3313\tacc:0.5250\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the performance on test set\n",
    "bert_model.load('data/bert_model.pt')\n",
    "bert_eval_metrics = bert_model.evaluate(bert_test_loader, bert_feature_idx_map, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 549/549\n",
      "loss: 6.0508\tf1:0.2614\tacc:0.4329\n"
     ]
    }
   ],
   "source": [
    "# Evalutating performance on the model without fine-tuining\n",
    "bert_non_finetuned = BertForQuestionAnswering.from_pretrained(bert_model_name)\n",
    "bert_non_finetuned.to(device)\n",
    "\n",
    "bert_newsqa_model = NewsQaModel(bert_non_finetuned)\n",
    "\n",
    "non_finetuned_eval_metrics = bert_newsqa_model.evaluate(bert_test_loader, bert_feature_idx_map, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrained-DistilBERT\n",
    "\n",
    "We use the distilbert-base-uncased-distilled-squad pretrained model which is trained specifically for question answering task and will be quick to fine-tune on our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining model name\n",
    "dbert_model_name = 'distilbert-base-uncased-distilled-squad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Getting the training, validation and test sets\n",
    "dbert_datasets = get_datasets(examples, dbert_model_name)\n",
    "dbert_train_set, dbert_val_set, dbert_test_set, dbert_feature_idx_map = dbert_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting data loaders\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "dbert_loaders = get_dataloaders(dbert_train_set, dbert_val_set, dbert_test_set, batch_size = BATCH_SIZE)\n",
    "dbert_train_loader, dbert_val_loader, dbert_test_loader = dbert_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5:\n",
      "Progress: [====================] 1921/1921  11m 16s\tloss: 3.9230\tf1: 0.2578\tacc: 0.3777\tval_loss: 3.7380\tval_f1: 0.2780\tval_acc: 0.3965\n",
      "Validation accuracy increased from 0.0000 to 0.3965, saving to models/distilbert.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 2/5:\n",
      "Progress: [====================] 1921/1921  11m 16s\tloss: 3.8655\tf1: 0.2588\tacc: 0.3855\tval_loss: 3.7188\tval_f1: 0.2911\tval_acc: 0.4216\n",
      "Validation accuracy increased from 0.3965 to 0.4216, saving to models/distilbert.pt\n",
      "\n",
      "\n",
      "\n",
      "Epoch 3/5:\n",
      "Progress: [====================] 1921/1921  11m 16s\tloss: 3.8613\tf1: 0.2589\tacc: 0.3875\tval_loss: 3.7073\tval_f1: 0.2893\tval_acc: 0.4138\n",
      "\n",
      "\n",
      "Epoch 4/5:\n",
      "Progress: [====================] 1921/1921  11m 16s\tloss: 3.8633\tf1: 0.2590\tacc: 0.3881\tval_loss: 3.7228\tval_f1: 0.2882\tval_acc: 0.4121\n",
      "\n",
      "\n",
      "Epoch 5/5:\n",
      "Progress: [====================] 1921/1921  11m 16s\tloss: 3.8660\tf1: 0.2593\tacc: 0.3864\tval_loss: 3.7113\tval_f1: 0.2896\tval_acc: 0.4192"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "dbert_model = finetune_model(dbert_model_name, dbert_train_loader, dbert_val_loader, dbert_feature_idx_map, \n",
    "                             device, epochs = EPOCHS, learning_rate = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 549/549\n",
      "loss: 3.6821\tf1:0.3028\tacc:0.4342\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the performance on test set\n",
    "dbert_model.load('data/distilbert_model.pt')\n",
    "dbert_eval_metrics = dbert_model.evaluate(dbert_test_loader, dbert_feature_idx_map, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [====================] 549/549\n",
      "loss: 6.4680\tf1:0.2837\tacc:0.4062\n"
     ]
    }
   ],
   "source": [
    "# Evalutating performance on the model without fine-tuining\n",
    "dbert_non_finetuned = DistilBertForQuestionAnswering.from_pretrained(dbert_model_name)\n",
    "dbert_non_finetuned.to(device)\n",
    "\n",
    "dbert_newsqa_model = NewsQaModel(dbert_non_finetuned)\n",
    "\n",
    "non_finetuned_eval_metrics = dbert_newsqa_model.evaluate(dbert_test_loader, dbert_feature_idx_map, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "The summary of the model performances on **test data**\n",
    "\n",
    "<p style=\"text-align: center; font-size: large; font-weight: bold;\"> BERT </p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> </th>\n",
    "        <th> Loss </th>\n",
    "        <th> F1-score </th>\n",
    "        <th> Accuracy </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th> Pre-trained model </th>\n",
    "        <td> 6.0508 </td>\n",
    "        <td> 0.2614 </td>\n",
    "        <td> 0.4329 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th> Fine-tuned model </th>\n",
    "        <td> 3.3887 </td>\n",
    "        <td> 0.3313 </td>\n",
    "        <td> 0.5250 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "<p style=\"text-align: center; font-size: large; font-weight: bold;\"> DistilBERT </p>\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th> </th>\n",
    "        <th> Loss </th>\n",
    "        <th> F1-score </th>\n",
    "        <th> Accuracy </th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th> Pre-trained model </th>\n",
    "        <td> 6.4680 </td>\n",
    "        <td> 0.2837 </td>\n",
    "        <td> 0.4062 </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <th> Fine-tuned model </th>\n",
    "        <td> 3.6821 </td>\n",
    "        <td> 0.3028 </td>\n",
    "        <td> 0.4342 </td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "In terms of accuracy, the DistilBERT fine-tuned model does almost the same as the original pre-trained BERT model. Overall too, the BERT model does better than DistilBERT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
